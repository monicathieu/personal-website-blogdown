---
title: "Research"
---


<div id="TOC">
<ul>
<li><a href="#research-tools">Research tools</a><ul>
<li><a href="#recruiting-online-participants">Recruiting online participants</a></li>
<li><a href="#running-behavioral-tasks-online">Running behavioral tasks online</a></li>
</ul></li>
<li><a href="#active-projects">Active projects</a><ul>
<li><a href="#individual-differences-in-age-perception">Individual differences in age perception</a></li>
<li><a href="#measurement-of-emotion-self-reporting">Measurement of emotion self-reporting</a></li>
</ul></li>
<li><a href="#previous-projects">Previous projects</a><ul>
<li><a href="#attention-memory-and-media-multitasking">Attention, memory, and media multitasking</a></li>
<li><a href="#healthy-aging-and-associative-memory">Healthy aging and associative memory</a></li>
</ul></li>
</ul>
</div>

<div id="research-tools" class="section level1">
<h1>Research tools</h1>
<div id="recruiting-online-participants" class="section level2">
<h2>Recruiting online participants</h2>
<p>I recently started using <a href="https://prolific.co">prolific.co</a>, a researcher-friendly website for online behavioral study recruitment that’s kind both to researchers and to participants. All my contacts with participants have been pleasant, and the Prolific support staff are so responsive and helpful. You can get a credit towards paying your first batch of participants if you sign up with <a href="https://www.prolific.co/r?ref=N8XQG222">my link here</a>!</p>
</div>
<div id="running-behavioral-tasks-online" class="section level2">
<h2>Running behavioral tasks online</h2>
<p>I use <a href="https://gorilla.sc">gorilla.sc</a>, a site that lets you build behavioral tasks both through GUI and code (their software is based on JavaScript/JQuery, though you don’t need to know either of those languages to use their tools). Their site is easy to use for JavaScript novices (like me), and still allows for full customization through added code. Their support staff are stellar as well! Instead of paying a subscription fee, you pay about a dollar per each participant who completes a task built on their platform. If you’d like to sign up, you can run twenty participants free with a referral. (email me for a referral link; they don’t currently have a referral link set up. PS: An academic email address is required to claim the bonus.)</p>
</div>
</div>
<div id="active-projects" class="section level1">
<h1>Active projects</h1>
<div id="individual-differences-in-age-perception" class="section level2">
<h2>Individual differences in age perception</h2>
<p>When we see another person’s face, we pretty quickly estimate their race, gender, and age just from looking at their face. When it comes to age in particular–we can estimate someone’s age in years, but we can also label them as “young” or “old”. <strong>How do people categorize faces of different ages, and do different people categorize age differently?</strong> We show participants a series of faces made to appear young, old, and somewhere in the middle, and ask them to label each face as “young” or “old”.</p>
{{% figure src="/img/quad1.gif" alt="Age and gender varying faces" position="center" style="border-radius: 6px;" caption="Some example age- and gender-morphed faces. (People don't actually see them animated in the study, just one at a time!)" captionPosition="center" %}}
<p>Preliminary results indicate that younger participants (say, in their 20s) tend to label the middle faces as “young”, but older participants (say, in their 60s) tend to label the middle faces as “old”. These results are exciting, and we hope to understand them better soon!</p>
</div>
<div id="measurement-of-emotion-self-reporting" class="section level2">
<h2>Measurement of emotion self-reporting</h2>
<p>What emotion are you feeling right now? When you’re experiencing some emotion, you could probably report what it is you’re feeling without much difficulty–this is something that humans can do readily. But <strong><em>how</em> do we turn our subjective emotional experience into self-report, and how does this relate to other parts of our emotional lives?</strong> We’ve developed a psychophysics-style paradigm where we show participants a series of brief, emotionally evocative GIFs, ask them to choose one of two emotion words to describe each experience (e.g. “neutral” or “fear”), and then fit their responses to a psychometric function. This way, we can find out how fearful (for example) a GIF has to be for an individual to say they feel fear (their psychometric threshold). We’ve also administered a series of surveys on things like mood, depression/anxiety tendencies, and more, so we can begin to examine how emotion-labeling patterns (as indexed by the psychometric task) predict facets of people’s social &amp; emotional lives.</p>
<p>We’ve run this first as a behavioral study, where results indicate that people who report being <em>more</em> emotionally expressive in their day-to-day lives have <em>lower</em> thresholds for reporting emotional responses to our GIFs (see <a href="https://osf.io/ubxtm/">this poster</a>). We’re also planning an fMRI study, so we can investigate whether people show systematic neural representations of subjective emotional experiences that correspond with the emotion terms that they use to describe said experiences.</p>
</div>
</div>
<div id="previous-projects" class="section level1">
<h1>Previous projects</h1>
<div id="attention-memory-and-media-multitasking" class="section level2">
<h2>Attention, memory, and media multitasking</h2>
<p>Media multitasking, or the act of engaging with multiple streams of media simultaneously, something. (If you’re listening to music while reading this, you’re engaging in media multitasking right now!) In the Stanford Memory Lab, we’ve demonstrated that individuals who chronically media multitask show a reduced working memory capacity, and that those people also show reduced long-term memory for the items they seem to be having more difficulty maintaining in working memory. <strong>What are the neural mechanisms subserving this relationship, and how do individual differences on a neural level track with trait media multitasking?</strong> It’s possible that the degree to which people favor the use of top-down, goal-directed attention vs. bottom-up, salience-reorienting attention might predict someone’s tendency to perform worse on these working memory and long-term memory tasks. We’re using fMRI to investigate how activation in top-down dorsal attention networks and bottom-up ventral attention networks might predict whether someone will successfully engage with and remember a given stimulus. In addition, we’re using EEG to investigate whether individual differences in power in certain EEG frequency bands, which might track top-down pre-stimulus preparatory attention, predict the degree to which someone will successfully engage with and remember a given stimulus.</p>
</div>
<div id="healthy-aging-and-associative-memory" class="section level2">
<h2>Healthy aging and associative memory</h2>
<p>Everyone experiences changes in cognition as they get older. We understand that some people develop neurodegenerative disorders as they age, such as Alzheimer’s disease and dementia, and that these pathological changes are associated with marked deficits in cognition. But this isn’t inevitable for people as they age. <strong>What kinds of cognitive changes should we expect as we age? What changes are nothing to worry about, and what changes are of medical concern?</strong> Existing research indicates that associative memory, the particular task of binding previously unrelated features into a single memory representation, may be a “canary in the coal mine” for pre-clinical cognitive decline. (When you run into an acquaintance at the grocery store, and you can remember the context in which you know them, but not what their name is, that’s your associative memory that’s failing you.) We’re currently running a large-scale individual differences study to try to describe how changes in cognition (associative memory in particular) relate to clinical markers of neurodegeneration in cognitively healthy older adults. We’re using various techniques to investigate the relationships between:</p>
<ul>
<li>age</li>
<li>Known Alzheimer’s biomarkers
<ul>
<li>APOE genotype</li>
<li>CSF beta-amyloid concentration</li>
<li>CSF phosphorylated tau concentration</li>
</ul></li>
<li>hippocampal subfield volume</li>
<li>BOLD correlates of associative encoding and retrieval</li>
<li>behavioral measures of associative memory</li>
</ul>
</div>
</div>
